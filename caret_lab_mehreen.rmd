---
title: "CARET_Lab"
output:
  pdf_document: default
  html_document: default
  word_document: default
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Package loading
```{r}
library(caret)
library(ggplot2)
library(lattice)
```

Load Data
```{r}
# attach the iris dataset to the environment
data(iris)
# rename the dataset
dataset <- iris
```

Task1: Create a Validation/Training Dataset
You need to split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset.
Hint: use createDataPartition function
```{r}
set.seed(123)  # for reproducibility
train_indices <- createDataPartition(dataset$Species, p = 0.8, list = FALSE)
train_data <- dataset[train_indices, ]
validation_data <- dataset[-train_indices, ]
```

Task2: Summarize Dataset
Use skimr library to summarize the dataset
```{r}
library(skimr)
skim(train_data)
```

Task3: split input and output
 It is the time to seperate the input attributes and  the output attributes. call the inputs attributes x and the output attribute (or class) y.
```{r}
x <- train_data[, 1:4]
y <- train_data[, 5]
```

Task4: Train Control for Validation Test

We will use 10-fold crossvalidation to estimate accuracy.
```{r}
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```

Task5: Model Training
Train 5 different algorithms using 'train' function:

- Linear Discriminant Analysis (LDA)
- Classification and Regression Trees (CART).
- k-Nearest Neighbors (kNN).
- Support Vector Machines (SVM) with a linear kernel.
- Random Forest (RF)

```{r}
set.seed(123)  # for reproducibility

# Linear Discriminant Analysis (LDA)
lda_model <- train(x, y, method = "lda", trControl = control, metric = metric)

# Classification and Regression Trees (CART)
cart_model <- train(x, y, method = "rpart", trControl = control, metric = metric)

# k-Nearest Neighbors (kNN)
knn_model <- train(x, y, method = "knn", trControl = control, metric = metric)

# Support Vector Machines (SVM)
svm_model <- train(x, y, method = "svmRadial", trControl = control, metric = metric)

# Random Forest (RF)
rf_model <- train(x, y, method = "rf", trControl = control, metric = metric)

# Create a list of models
models <- list(
  "Linear Discriminant Analysis (LDA)" = lda_model,
  "Classification and Regression Trees (CART)" = cart_model,
  "k-Nearest Neighbors (kNN)" = knn_model,
  "Support Vector Machines (SVM)" = svm_model,
  "Random Forest (RF)" = rf_model
)


```

Task6: Select the Best Model
We now have 5 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate.
Use resamples function to complete this task

```{r}
set.seed(123)  # for reproducibility
resamples_results <- resamples(models)
summary(resamples_results)
```
What was the most accurate model?
The most accurate model based on the summary of resamples is the Linear Discriminant Analysis (LDA) model. It achieved the highest mean accuracy of 0.9833333 and kappa value of 0.9750.

Task7: Make Prediction (Confusion Matrix)
Now we want to get an idea of the accuracy of the best model on our validation set. Use 'predict' and confusionMatrix functions to complete this task.

```{r}
# Get the best model
best_model <- models$`Linear Discriminant Analysis (LDA)`

# Predict on the validation set
predictions <- predict(best_model, newdata = validation_data)

# Create the confusion matrix
confusionMatrix(predictions, validation_data$Species)
```

